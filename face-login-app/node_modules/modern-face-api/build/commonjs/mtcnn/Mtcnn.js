"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.Mtcnn = void 0;
const tf = require("@tensorflow/tfjs-core");
const classes_1 = require("../classes");
const FaceDetection_1 = require("../classes/FaceDetection");
const FaceLandmarks5_1 = require("../classes/FaceLandmarks5");
const dom_1 = require("../dom");
const factories_1 = require("../factories");
const NeuralNetwork_1 = require("../NeuralNetwork");
const bgrToRgbTensor_1 = require("./bgrToRgbTensor");
const config_1 = require("./config");
const extractParams_1 = require("./extractParams");
const extractParamsFromWeigthMap_1 = require("./extractParamsFromWeigthMap");
const getSizesForScale_1 = require("./getSizesForScale");
const MtcnnOptions_1 = require("./MtcnnOptions");
const pyramidDown_1 = require("./pyramidDown");
const stage1_1 = require("./stage1");
const stage2_1 = require("./stage2");
const stage3_1 = require("./stage3");
class Mtcnn extends NeuralNetwork_1.NeuralNetwork {
    constructor() {
        super('Mtcnn');
    }
    async load(weightsOrUrl) {
        console.warn('mtcnn is deprecated and will be removed soon');
        return super.load(weightsOrUrl);
    }
    async loadFromDisk(filePath) {
        console.warn('mtcnn is deprecated and will be removed soon');
        return super.loadFromDisk(filePath);
    }
    async forwardInput(input, forwardParams = {}) {
        const { params } = this;
        if (!params) {
            throw new Error('Mtcnn - load model before inference');
        }
        const inputCanvas = input.canvases[0];
        if (!inputCanvas) {
            throw new Error('Mtcnn - inputCanvas is not defined, note that passing tensors into Mtcnn.forwardInput is not supported yet.');
        }
        const stats = {};
        const tsTotal = Date.now();
        const imgTensor = tf.tidy(() => (0, bgrToRgbTensor_1.bgrToRgbTensor)(tf.cast(tf.expandDims(tf.browser.fromPixels(inputCanvas)), 'float32')));
        const onReturn = (results) => {
            // dispose tensors on return
            imgTensor.dispose();
            stats.total = Date.now() - tsTotal;
            return { results, stats };
        };
        const [height, width] = imgTensor.shape.slice(1);
        const { minFaceSize, scaleFactor, maxNumScales, scoreThresholds, scaleSteps } = new MtcnnOptions_1.MtcnnOptions(forwardParams);
        const scales = (scaleSteps || (0, pyramidDown_1.pyramidDown)(minFaceSize, scaleFactor, [height, width]))
            .filter(scale => {
            const sizes = (0, getSizesForScale_1.getSizesForScale)(scale, [height, width]);
            return Math.min(sizes.width, sizes.height) > config_1.CELL_SIZE;
        })
            .slice(0, maxNumScales);
        stats.scales = scales;
        stats.pyramid = scales.map(scale => (0, getSizesForScale_1.getSizesForScale)(scale, [height, width]));
        let ts = Date.now();
        const out1 = await (0, stage1_1.stage1)(imgTensor, scales, scoreThresholds[0], params.pnet, stats);
        stats.total_stage1 = Date.now() - ts;
        if (!out1.boxes.length) {
            return onReturn([]);
        }
        stats.stage2_numInputBoxes = out1.boxes.length;
        // using the inputCanvas to extract and resize the image patches, since it is faster
        // than doing this on the gpu
        ts = Date.now();
        const out2 = await (0, stage2_1.stage2)(inputCanvas, out1.boxes, scoreThresholds[1], params.rnet, stats);
        stats.total_stage2 = Date.now() - ts;
        if (!out2.boxes.length) {
            return onReturn([]);
        }
        stats.stage3_numInputBoxes = out2.boxes.length;
        ts = Date.now();
        const out3 = await (0, stage3_1.stage3)(inputCanvas, out2.boxes, scoreThresholds[2], params.onet, stats);
        stats.total_stage3 = Date.now() - ts;
        const results = out3.boxes.map((box, idx) => (0, factories_1.extendWithFaceLandmarks)((0, factories_1.extendWithFaceDetection)({}, new FaceDetection_1.FaceDetection(out3.scores[idx], new classes_1.Rect(box.left / width, box.top / height, box.width / width, box.height / height), {
            height,
            width,
        })), new FaceLandmarks5_1.FaceLandmarks5(out3.points[idx].map(pt => pt.sub(new classes_1.Point(box.left, box.top)).div(new classes_1.Point(box.width, box.height))), { width: box.width, height: box.height })));
        return onReturn(results);
    }
    async forward(input, forwardParams = {}) {
        return (await this.forwardInput(await (0, dom_1.toNetInput)(input), forwardParams)).results;
    }
    async forwardWithStats(input, forwardParams = {}) {
        return this.forwardInput(await (0, dom_1.toNetInput)(input), forwardParams);
    }
    getDefaultModelName() {
        return 'mtcnn_model';
    }
    extractParamsFromWeigthMap(weightMap) {
        return (0, extractParamsFromWeigthMap_1.extractParamsFromWeigthMap)(weightMap);
    }
    extractParams(weights) {
        return (0, extractParams_1.extractParams)(weights);
    }
}
exports.Mtcnn = Mtcnn;
