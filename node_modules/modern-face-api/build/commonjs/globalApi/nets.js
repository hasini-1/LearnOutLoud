"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.detectLandmarks = exports.locateFaces = exports.loadFaceDetectionModel = exports.loadAgeGenderModel = exports.loadFaceExpressionModel = exports.loadFaceRecognitionModel = exports.loadFaceLandmarkTinyModel = exports.loadFaceLandmarkModel = exports.loadTinyYolov2Model = exports.loadMtcnnModel = exports.loadTinyFaceDetectorModel = exports.loadSsdMobilenetv1Model = exports.predictAgeAndGender = exports.recognizeFaceExpressions = exports.computeFaceDescriptor = exports.detectFaceLandmarksTiny = exports.detectFaceLandmarks = exports.mtcnn = exports.tinyYolov2 = exports.tinyFaceDetector = exports.ssdMobilenetv1 = exports.nets = void 0;
const AgeGenderNet_1 = require("../ageGenderNet/AgeGenderNet");
const FaceExpressionNet_1 = require("../faceExpressionNet/FaceExpressionNet");
const FaceLandmark68Net_1 = require("../faceLandmarkNet/FaceLandmark68Net");
const FaceLandmark68TinyNet_1 = require("../faceLandmarkNet/FaceLandmark68TinyNet");
const FaceRecognitionNet_1 = require("../faceRecognitionNet/FaceRecognitionNet");
const Mtcnn_1 = require("../mtcnn/Mtcnn");
const SsdMobilenetv1_1 = require("../ssdMobilenetv1/SsdMobilenetv1");
const TinyFaceDetector_1 = require("../tinyFaceDetector/TinyFaceDetector");
const tinyYolov2_1 = require("../tinyYolov2");
exports.nets = {
    ssdMobilenetv1: new SsdMobilenetv1_1.SsdMobilenetv1(),
    tinyFaceDetector: new TinyFaceDetector_1.TinyFaceDetector(),
    tinyYolov2: new tinyYolov2_1.TinyYolov2(),
    mtcnn: new Mtcnn_1.Mtcnn(),
    faceLandmark68Net: new FaceLandmark68Net_1.FaceLandmark68Net(),
    faceLandmark68TinyNet: new FaceLandmark68TinyNet_1.FaceLandmark68TinyNet(),
    faceRecognitionNet: new FaceRecognitionNet_1.FaceRecognitionNet(),
    faceExpressionNet: new FaceExpressionNet_1.FaceExpressionNet(),
    ageGenderNet: new AgeGenderNet_1.AgeGenderNet(),
};
/**
 * Attempts to detect all faces in an image using SSD Mobilenetv1 Network.
 *
 * @param input The input image.
 * @param options (optional, default: see SsdMobilenetv1Options constructor for default parameters).
 * @returns Bounding box of each face with score.
 */
const ssdMobilenetv1 = (input, options) => exports.nets.ssdMobilenetv1.locateFaces(input, options);
exports.ssdMobilenetv1 = ssdMobilenetv1;
/**
 * Attempts to detect all faces in an image using the Tiny Face Detector.
 *
 * @param input The input image.
 * @param options (optional, default: see TinyFaceDetectorOptions constructor for default parameters).
 * @returns Bounding box of each face with score.
 */
const tinyFaceDetector = (input, options) => exports.nets.tinyFaceDetector.locateFaces(input, options);
exports.tinyFaceDetector = tinyFaceDetector;
/**
 * Attempts to detect all faces in an image using the Tiny Yolov2 Network.
 *
 * @param input The input image.
 * @param options (optional, default: see TinyYolov2Options constructor for default parameters).
 * @returns Bounding box of each face with score.
 */
const tinyYolov2 = (input, options) => exports.nets.tinyYolov2.locateFaces(input, options);
exports.tinyYolov2 = tinyYolov2;
/**
 * Attempts to detect all faces in an image and the 5 point face landmarks
 * of each detected face using the MTCNN Network.
 *
 * @param input The input image.
 * @param options (optional, default: see MtcnnOptions constructor for default parameters).
 * @returns Bounding box of each face with score and 5 point face landmarks.
 */
const mtcnn = (input, options) => exports.nets.mtcnn.forward(input, options);
exports.mtcnn = mtcnn;
/**
 * Detects the 68 point face landmark positions of the face shown in an image.
 *
 * @param inputs The face image extracted from the bounding box of a face. Can
 * also be an array of input images, which will be batch processed.
 * @returns 68 point face landmarks or array thereof in case of batch input.
 */
const detectFaceLandmarks = (input) => exports.nets.faceLandmark68Net.detectLandmarks(input);
exports.detectFaceLandmarks = detectFaceLandmarks;
/**
 * Detects the 68 point face landmark positions of the face shown in an image
 * using a tinier version of the 68 point face landmark model, which is slightly
 * faster at inference, but also slightly less accurate.
 *
 * @param inputs The face image extracted from the bounding box of a face. Can
 * also be an array of input images, which will be batch processed.
 * @returns 68 point face landmarks or array thereof in case of batch input.
 */
const detectFaceLandmarksTiny = (input) => exports.nets.faceLandmark68TinyNet.detectLandmarks(input);
exports.detectFaceLandmarksTiny = detectFaceLandmarksTiny;
/**
 * Computes a 128 entry vector (face descriptor / face embeddings) from the face shown in an image,
 * which uniquely represents the features of that persons face. The computed face descriptor can
 * be used to measure the similarity between faces, by computing the euclidean distance of two
 * face descriptors.
 *
 * @param inputs The face image extracted from the aligned bounding box of a face. Can
 * also be an array of input images, which will be batch processed.
 * @returns Face descriptor with 128 entries or array thereof in case of batch input.
 */
const computeFaceDescriptor = (input) => exports.nets.faceRecognitionNet.computeFaceDescriptor(input);
exports.computeFaceDescriptor = computeFaceDescriptor;
/**
 * Recognizes the facial expressions from a face image.
 *
 * @param inputs The face image extracted from the bounding box of a face. Can
 * also be an array of input images, which will be batch processed.
 * @returns Facial expressions with corresponding probabilities or array thereof in case of batch input.
 */
const recognizeFaceExpressions = (input) => exports.nets.faceExpressionNet.predictExpressions(input);
exports.recognizeFaceExpressions = recognizeFaceExpressions;
/**
 * Predicts age and gender from a face image.
 *
 * @param inputs The face image extracted from the bounding box of a face. Can
 * also be an array of input images, which will be batch processed.
 * @returns Predictions with age, gender and gender probability or array thereof in case of batch input.
 */
const predictAgeAndGender = (input) => exports.nets.ageGenderNet.predictAgeAndGender(input);
exports.predictAgeAndGender = predictAgeAndGender;
const loadSsdMobilenetv1Model = (url) => exports.nets.ssdMobilenetv1.load(url);
exports.loadSsdMobilenetv1Model = loadSsdMobilenetv1Model;
const loadTinyFaceDetectorModel = (url) => exports.nets.tinyFaceDetector.load(url);
exports.loadTinyFaceDetectorModel = loadTinyFaceDetectorModel;
const loadMtcnnModel = (url) => exports.nets.mtcnn.load(url);
exports.loadMtcnnModel = loadMtcnnModel;
const loadTinyYolov2Model = (url) => exports.nets.tinyYolov2.load(url);
exports.loadTinyYolov2Model = loadTinyYolov2Model;
const loadFaceLandmarkModel = (url) => exports.nets.faceLandmark68Net.load(url);
exports.loadFaceLandmarkModel = loadFaceLandmarkModel;
const loadFaceLandmarkTinyModel = (url) => exports.nets.faceLandmark68TinyNet.load(url);
exports.loadFaceLandmarkTinyModel = loadFaceLandmarkTinyModel;
const loadFaceRecognitionModel = (url) => exports.nets.faceRecognitionNet.load(url);
exports.loadFaceRecognitionModel = loadFaceRecognitionModel;
const loadFaceExpressionModel = (url) => exports.nets.faceExpressionNet.load(url);
exports.loadFaceExpressionModel = loadFaceExpressionModel;
const loadAgeGenderModel = (url) => exports.nets.ageGenderNet.load(url);
exports.loadAgeGenderModel = loadAgeGenderModel;
// backward compatibility
exports.loadFaceDetectionModel = exports.loadSsdMobilenetv1Model;
exports.locateFaces = exports.ssdMobilenetv1;
exports.detectLandmarks = exports.detectFaceLandmarks;
