<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>LearnOutLoud · Voice-Guided Face Login for Blind Users</title>

<!-- Face API library -->
<script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

<link href="https://fonts.googleapis.com/css2?family=Syne:wght@800&family=DM+Sans:wght@400;500&display=swap" rel="stylesheet">

<style>
*{box-sizing:border-box;margin:0;padding:0;}
:root{
--bg:#07070f;
--purple:#7b2ff7;
--cyan:#00d4ff;
--text:#f0f0f8;
--glow:0 0 30px rgba(123,47,247,0.5);
}
body{
background:var(--bg);
color:var(--text);
font-family:'DM Sans',sans-serif;
min-height:100vh;
display:flex;
flex-direction:column;
align-items:center;
justify-content:center;
position:relative;
}
.video-container {
position:relative;
width:320px;
height:320px;
display:flex;
align-items:center;
justify-content:center;
}
.orb-video{
width:320px;
height:320px;
border-radius:50%;
object-fit:cover;
box-shadow:var(--glow);
border:3px solid rgba(0,212,255,0.3);
transition: all 0.3s ease;
}
.voice-active{
animation:pulseGlow 1.2s infinite;
border-color:var(--cyan);
}
@keyframes pulseGlow{
0%{box-shadow:0 0 30px var(--purple);}
50%{box-shadow:0 0 90px var(--cyan);}
100%{box-shadow:0 0 30px var(--purple);}
}
.face-guide{
position:absolute;
top:50%;
left:50%;
transform:translate(-50%, -50%);
width:320px;
height:320px;
border-radius:50%;
border:2px dashed rgba(0,212,255,0.6);
pointer-events:none;
box-shadow:0 0 20px rgba(0,212,255,0.3);
z-index:10;
}
.hero-title{
font-family:'Syne',sans-serif;
font-size:2rem;
margin-top:1.5rem;
letter-spacing:2px;
background:linear-gradient(135deg,#fff 0%,var(--cyan)80%);
-webkit-background-clip:text;
-webkit-text-fill-color:transparent;
}
.status-msg{
margin-top:1.2rem;
color:var(--cyan);
font-weight:500;
letter-spacing:1px;
text-transform:uppercase;
font-size:1.2rem;
min-height:3rem;
text-shadow:0 0 10px rgba(0,212,255,0.5);
}

/* Instruction hint */
.instruction-hint {
margin-top: 2rem;
padding: 1rem;
background: rgba(0,0,0,0.5);
border-radius: 10px;
font-size: 1.1rem;
text-align: center;
border: 1px solid var(--cyan);
}
.space-command {
color: var(--cyan);
font-weight: bold;
font-size: 1.3rem;
}

/* Voice registration UI - simplified for blind users */
.voice-status {
margin-top: 1rem;
font-size: 1.2rem;
color: var(--cyan);
min-height: 2rem;
text-align: center;
}
.listening-indicator {
display: none;
align-items: center;
justify-content: center;
gap: 0.5rem;
margin: 1rem 0;
}
.listening-indicator.visible {
display: flex;
}
.listening-dot {
width: 12px;
height: 12px;
background: var(--cyan);
border-radius: 50%;
animation: pulse 1s infinite;
}
@keyframes pulse {
0% { opacity: 0.3; transform: scale(1); }
50% { opacity: 1; transform: scale(1.2); }
100% { opacity: 0.3; transform: scale(1); }
}

/* User greeting */
.user-greeting {
margin-top: 1rem;
font-size: 1.3rem;
color: var(--cyan);
text-shadow: 0 0 10px var(--cyan);
display: none;
}
.user-greeting.visible {
display: block;
}

/* Loading indicator */
.loading {
margin-top: 1rem;
color: var(--cyan);
display: none;
}
.loading.visible {
display: block;
}

/* Screen reader only */
.sr-only {
position: absolute;
width: 1px;
height: 1px;
padding: 0;
margin: -1px;
overflow: hidden;
clip: rect(0,0,0,0);
border: 0;
}

/* API Status */
.api-status {
position: fixed;
top: 10px;
right: 10px;
font-size: 0.8rem;
padding: 0.3rem 0.8rem;
border-radius: 20px;
}
.api-status.connected {
background: rgba(0,255,0,0.2);
color: #00ff00;
}
.api-status.disconnected {
background: rgba(255,0,0,0.2);
color: #ff0000;
}
</style>
</head>
<body>

<!-- Screen reader announcements -->
<div class="sr-only" id="screenReaderAnnounce" aria-live="polite" aria-atomic="true"></div>
<div class="sr-only" id="screenReaderAlert" aria-live="assertive" aria-atomic="true"></div>

<div class="video-container">
  <div class="face-guide" aria-label="Face positioning guide circle"></div>
  <video id="faceVideo" class="orb-video" autoplay playsinline aria-label="Camera preview for face detection"></video>
</div>

<canvas id="faceCanvas" style="display:none;"></canvas>

<h1 class="hero-title">LearnOutLoud</h1>
<p id="status" class="status-msg" role="status">Loading face recognition...</p>

<!-- Voice status indicator (visual feedback) -->
<div class="voice-status" id="voiceStatus"></div>
<div class="listening-indicator" id="listeningIndicator">
  <div class="listening-dot"></div>
  <div class="listening-dot"></div>
  <div class="listening-dot"></div>
  <span>Listening...</span>
</div>

<!-- User greeting -->
<div class="user-greeting" id="userGreeting"></div>

<!-- Loading indicator -->
<div class="loading" id="loading">Processing...</div>

<!-- Instruction hint -->
<div class="instruction-hint" id="instructionHint">
  <div>⚡ <span class="space-command">SPACE BAR</span> to start/stop</div>
  <div>Voice guidance will direct you</div>
  <div>Your face will be checked automatically</div>
</div>

<!-- API Status -->
<div class="api-status disconnected" id="apiStatus">API: Connecting...</div>

<script>
(function(){

const video = document.getElementById("faceVideo");
const canvas = document.getElementById("faceCanvas");
const ctx = canvas.getContext("2d");
const statusEl = document.getElementById("status");
const faceGuide = document.querySelector('.face-guide');
const screenReaderAnnounce = document.getElementById('screenReaderAnnounce');
const screenReaderAlert = document.getElementById('screenReaderAlert');
const voiceStatus = document.getElementById('voiceStatus');
const listeningIndicator = document.getElementById('listeningIndicator');
const userGreeting = document.getElementById('userGreeting');
const loading = document.getElementById('loading');
const apiStatus = document.getElementById('apiStatus');

// API Configuration
const API_URL = 'http://localhost:5000/api';

let isActive = false;
let mode = "idle"; // idle, detecting, registering, verifying
let cameraStream = null;
let detectionInterval = null;
let isSpeaking = false;
let modelsLoaded = false;
let currentDescriptor = null;
let lastGuidance = "";
let noFaceCount = 0;
let speechQueue = [];
let isProcessingQueue = false;
let voiceRecognition = null;
let pendingName = "";
let welcomeSpoken = false;
let verificationMode = false;
let expectedName = "";
let isListeningForName = false;
let isListeningForConfirmation = false;

// Initialize speech synthesis voices
let speechVoices = [];
window.speechSynthesis.onvoiceschanged = () => {
  speechVoices = window.speechSynthesis.getVoices();
};

// Initialize voice recognition
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
if (SpeechRecognition) {
  voiceRecognition = new SpeechRecognition();
  voiceRecognition.continuous = false;
  voiceRecognition.interimResults = true;
  voiceRecognition.lang = 'en-US';
  voiceRecognition.maxAlternatives = 5;
}

// Announce function for blind users
function announce(message, isAlert = false, priority = false) {
  console.log("ANNOUNCE:", message);
  
  if (isAlert) {
    screenReaderAlert.textContent = message;
  } else {
    screenReaderAnnounce.textContent = message;
  }
  
  // Update visual status for partial sight
  voiceStatus.textContent = message;
  
  if (priority) {
    speechQueue.unshift(message);
  } else {
    speechQueue.push(message);
  }
  
  if (!isProcessingQueue) {
    processSpeechQueue();
  }
}

// Process speech queue
async function processSpeechQueue() {
  if (speechQueue.length === 0) {
    isProcessingQueue = false;
    return;
  }
  
  isProcessingQueue = true;
  const message = speechQueue.shift();
  await speakText(message);
  processSpeechQueue();
}

// Speak function
function speakText(text) {
  return new Promise((resolve) => {
    try {
      isSpeaking = true;
      
      const utter = new SpeechSynthesisUtterance(text);
      
      const preferredVoice = speechVoices.find(voice => 
        voice.lang.includes('en') && (voice.name.includes('Google') || voice.name.includes('Natural'))
      );
      if (preferredVoice) {
        utter.voice = preferredVoice;
      }
      
      utter.rate = 0.9;
      utter.pitch = 1;
      utter.volume = 1;

      utter.onstart = () => {
        video.classList.add("voice-active");
        faceGuide.style.borderColor = '#00d4ff';
      };

      utter.onend = () => {
        video.classList.remove("voice-active");
        faceGuide.style.borderColor = 'rgba(0,212,255,0.6)';
        isSpeaking = false;
        resolve();
      };

      utter.onerror = (e) => {
        console.log("Speech error:", e);
        isSpeaking = false;
        resolve();
      };

      speechSynthesis.cancel();
      speechSynthesis.speak(utter);
    } catch(e) {
      console.log("Speak function error:", e);
      isSpeaking = false;
      resolve();
    }
  });
}

// Play beep
function playBeep() {
  try {
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const oscillator = audioContext.createOscillator();
    const gainNode = audioContext.createGain();
    
    oscillator.connect(gainNode);
    gainNode.connect(audioContext.destination);
    
    oscillator.frequency.value = 800;
    gainNode.gain.value = 0.1;
    
    oscillator.start();
    oscillator.stop(audioContext.currentTime + 0.1);
  } catch(e) {
    console.log("Beep error:", e);
  }
}

// Load models
async function loadModels() {
  try {
    statusEl.innerText = "Loading AI models...";
    
    const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
    
    await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
    await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
    await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
    
    modelsLoaded = true;
    statusEl.innerText = "Press SPACE to start";
    
    // Welcome message for blind users - speaks every time page loads
    announce("Welcome to LearnOutLoud. Face recognition models are now activated and ready. Press space bar to start.", true, true);
    
    checkAPIConnection();
    
    return true;
  } catch (error) {
    console.error("Error loading models:", error);
    statusEl.innerText = "Model loading failed";
    announce("Failed to load face recognition models. Please refresh the page.", true, true);
    return false;
  }
}

// Check API connection
async function checkAPIConnection() {
  try {
    const response = await fetch('http://localhost:5000/api/users');
    
    if (response.ok) {
      apiStatus.textContent = 'API: Connected';
      apiStatus.className = 'api-status connected';
      return true;
    } else {
      apiStatus.textContent = 'API: Error';
      apiStatus.className = 'api-status disconnected';
      return false;
    }
  } catch (error) {
    apiStatus.textContent = 'API: Disconnected';
    apiStatus.className = 'api-status disconnected';
    announce("Cannot connect to server. Make sure backend is running on port 5000.", true, true);
    return false;
  }
}

// Start listening for voice input
function startListening(prompt, callback) {
  if (!voiceRecognition) {
    announce("Voice recognition not supported.", true, true);
    return;
  }
  
  listeningIndicator.classList.add('visible');
  voiceStatus.textContent = prompt;
  
  voiceRecognition.onresult = (event) => {
    let finalTranscript = '';
    let interimTranscript = '';
    
    for (let i = event.resultIndex; i < event.results.length; i++) {
      const transcript = event.results[i][0].transcript;
      if (event.results[i].isFinal) {
        finalTranscript += transcript;
      } else {
        interimTranscript += transcript;
      }
    }
    
    if (interimTranscript) {
      voiceStatus.textContent = `Heard: ${interimTranscript}...`;
    }
    
    if (finalTranscript) {
      listeningIndicator.classList.remove('visible');
      callback(finalTranscript.trim().toLowerCase());
    }
  };
  
  voiceRecognition.onend = () => {
    if (listeningIndicator.classList.contains('visible')) {
      // Restart if still listening
      voiceRecognition.start();
    }
  };
  
  voiceRecognition.start();
}

// Handle name registration flow
function handleNameRegistration() {
  isListeningForName = true;
  announce("Please say your name clearly after the beep.", false, true);
  playBeep();
  
  startListening("Listening for your name...", (spokenName) => {
    isListeningForName = false;
    pendingName = spokenName;
    voiceStatus.textContent = `You said: ${pendingName}`;
    announce(`I heard ${pendingName}. Is that correct? Please say yes or no.`, false, true);
    
    // Listen for confirmation
    isListeningForConfirmation = true;
    startListening("Listening for yes or no...", (response) => {
      isListeningForConfirmation = false;
      
      if (response.includes('yes') || response.includes('yeah') || response.includes('yep') || 
          response.includes('correct') || response.includes('right') || response.includes('ok')) {
        announce("You said yes. Registering your face.", false, true);
        registerWithName(pendingName);
      } else if (response.includes('no') || response.includes('nope') || response.includes('incorrect') || 
                 response.includes('wrong') || response.includes('try again')) {
        announce("You said no. Let's try again.", false, true);
        setTimeout(() => handleNameRegistration(), 1000);
      } else {
        announce("I didn't understand. Please say yes or no clearly.", true, true);
        setTimeout(() => {
          isListeningForConfirmation = true;
          startListening("Listening for yes or no...", (retryResponse) => {
            // Recursive handling would go here, but for simplicity we'll restart
            handleNameRegistration();
          });
        }, 1000);
      }
    });
  });
}

// Handle verification flow - WITHOUT speaking the name
function handleVerification(expectedName) {
  // Store the expected name for comparison
  const correctName = expectedName.toLowerCase();
  
  // Don't speak the name - just ask to say it
  announce("Your face has been recognized. Please say your name to verify your identity.", false, true);
  playBeep();
  
  startListening("Listening for your name...", (spokenName) => {
    if (spokenName.toLowerCase() === correctName) {
      // Name matches silently - don't announce the name
      announce("Name verified. Welcome back!", false, true);
      
      // Show greeting visually but don't speak it
      userGreeting.textContent = `Welcome back!`;
      userGreeting.classList.add('visible');
      statusEl.innerText = `Welcome back!`;
      
      video.classList.add("voice-active");
      
      playBeep();
      setTimeout(() => playBeep(), 200);
      setTimeout(() => playBeep(), 400);
      
      setTimeout(() => {
        announce("Redirecting to home page.");
        window.location.href = "home.html";
      }, 2000);
    } else {
      announce("Name does not match. Please try again.", true, true);
      setTimeout(() => handleVerification(expectedName), 2000);
    }
  });
}

// Register new user
async function registerWithName(name) {
  if (!currentDescriptor) {
    announce("No face detected. Please try again.", true, true);
    return;
  }

  loading.classList.add('visible');
  statusEl.innerText = "Registering...";
  announce(`Registering. Please wait.`, false, true);  // Don't speak the name

  try {
    const response = await fetch(`${API_URL}/face/register`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ 
        name: name,
        descriptor: currentDescriptor
      })
    });
    
    const result = await response.json();
    loading.classList.remove('visible');
    
    if (result.success) {
      userGreeting.textContent = `Welcome!`;
      userGreeting.classList.add('visible');
      statusEl.innerText = `Welcome!`;
      announce(`Registration successful! Welcome!`, false, true);  // Don't speak the name
      
      video.classList.add("voice-active");
      
      playBeep();
      setTimeout(() => playBeep(), 200);
      setTimeout(() => playBeep(), 400);
      
      setTimeout(() => {
        announce("Redirecting to home page.");
        window.location.href = "home.html";
      }, 2000);
      
    } else {
      announce(`Registration failed: ${result.error || 'Please try again'}`, true, true);
      setTimeout(() => handleNameRegistration(), 1000);
    }
  } catch (error) {
    console.error("Registration error:", error);
    announce("Registration failed. Please try again.", true, true);
    loading.classList.remove('visible');
    setTimeout(() => handleNameRegistration(), 1000);
  }
}

// Camera function
async function startCamera() {
  try {
    cameraStream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: { ideal: 640 },
        height: { ideal: 480 },
        facingMode: "user"
      }
    });
    video.srcObject = cameraStream;
    await video.play();
    announce("Camera started. I will guide you.", false, true);
    playBeep();
    return true;
  } catch(e) {
    announce("Camera access denied. Check permissions.", true, true);
    return false;
  }
}

// Stop camera
function stopCamera() {
  if(cameraStream) {
    cameraStream.getTracks().forEach(t => t.stop());
    cameraStream = null;
  }
}

// Get face guidance
function getFaceGuidance(detection) {
  const box = detection.detection.box;
  const videoWidth = video.videoWidth;
  const videoHeight = video.videoHeight;
  
  const faceCenterX = box.x + box.width / 2;
  const faceCenterY = box.y + box.height / 2;
  const videoCenterX = videoWidth / 2;
  const videoCenterY = videoHeight / 2;
  
  const faceArea = box.width * box.height;
  const frameArea = videoWidth * videoHeight;
  const faceRatio = faceArea / frameArea;
  
  if (faceRatio < 0.05) return { aligned: false, guidance: "Move closer" };
  if (faceRatio > 0.5) return { aligned: false, guidance: "Move back" };
  
  const horizontalDiff = faceCenterX - videoCenterX;
  const verticalDiff = faceCenterY - videoCenterY;
  
  const HORIZONTAL_THRESHOLD = videoWidth * 0.15;
  const VERTICAL_THRESHOLD = videoHeight * 0.15;
  
  if (Math.abs(horizontalDiff) > HORIZONTAL_THRESHOLD) {
    return { aligned: false, guidance: horizontalDiff > 0 ? "Move left" : "Move right" };
  }
  
  if (Math.abs(verticalDiff) > VERTICAL_THRESHOLD) {
    return { aligned: false, guidance: verticalDiff > 0 ? "Move up" : "Move down" };
  }
  
  return { aligned: true, guidance: "Perfect!" };
}

// Detect and check face
async function detectAndCheck() {
  if (!modelsLoaded || !video.videoWidth) return;

  try {
    const options = new faceapi.TinyFaceDetectorOptions({
      inputSize: 320,
      scoreThreshold: 0.3
    });
    
    const detection = await faceapi
      .detectSingleFace(video, options)
      .withFaceLandmarks()
      .withFaceDescriptor();

    if (!detection) {
      statusEl.innerText = "No face detected";
      noFaceCount++;
      
      if (noFaceCount % 10 === 0) {
        announce("No face detected. Please look at the camera.");
        playBeep();
      }
      return;
    }

    noFaceCount = 0;
    const guidance = getFaceGuidance(detection);
    
    if (!guidance.aligned) {
      statusEl.innerText = guidance.guidance;
      
      if (guidance.guidance !== lastGuidance) {
        announce(guidance.guidance);
        lastGuidance = guidance.guidance;
        playBeep();
      }
      return;
    }

    if (lastGuidance !== "perfect") {
      announce("Perfect! Checking your face...");
      lastGuidance = "perfect";
      playBeep();
      playBeep();
    }

    loading.classList.add('visible');
    statusEl.innerText = "Checking face...";
    
    currentDescriptor = Array.from(detection.descriptor);
    
    const response = await fetch(`${API_URL}/face/check`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ descriptor: currentDescriptor })
    });
    
    const result = await response.json();
    loading.classList.remove('visible');
    
    if (result.success && result.exists) {
      // Face exists - verify name (without speaking it)
      clearInterval(detectionInterval);
      handleVerification(result.name);
      
    } else {
      // New face - register
      clearInterval(detectionInterval);
      handleNameRegistration();
    }
    
  } catch (error) {
    console.error("Detection error:", error);
    loading.classList.remove('visible');
    statusEl.innerText = "Error detecting face";
  }
}

// Start detection
function startDetection() {
  mode = "detecting";
  lastGuidance = "";
  noFaceCount = 0;
  statusEl.innerText = "Detecting face...";
  announce("I am now looking for your face. Please look at the camera.", false, true);
  
  if (detectionInterval) clearInterval(detectionInterval);
  detectionInterval = setInterval(detectAndCheck, 1500);
}

// Stop system
function stopSystem() {
  speechSynthesis.cancel();
  clearInterval(detectionInterval);
  stopCamera();
  
  if (voiceRecognition) {
    try { voiceRecognition.stop(); } catch(e) {}
  }
  
  mode = "idle";
  isActive = false;
  isSpeaking = false;
  statusEl.innerText = "Press SPACE to start";
  listeningIndicator.classList.remove('visible');
  userGreeting.classList.remove('visible');
  loading.classList.remove('visible');
  voiceStatus.textContent = "";
  
  video.classList.remove("voice-active");
  faceGuide.style.borderColor = 'rgba(0,212,255,0.6)';
  
  announce("System stopped. Press space bar to start again.", false, true);
}

// SPACE BAR CONTROL - only button needed
window.addEventListener('keydown', async function(e) {
  if(e.code === "Space") {
    e.preventDefault();
    
    if (!isActive) {
      if (!modelsLoaded) {
        announce("Models still loading. Please wait.", true, true);
        return;
      }
      
      const apiConnected = await checkAPIConnection();
      if (!apiConnected) return;
      
      isActive = true;
      statusEl.innerText = "Starting camera...";
      announce("Starting camera. Please wait.", false, true);
      
      const cameraStarted = await startCamera();
      if (cameraStarted) {
        setTimeout(() => startDetection(), 1500);
      } else {
        isActive = false;
      }
    } else {
      stopSystem();
    }
  }
}, false);

// Prevent page scroll on space
window.addEventListener('keydown', function(e) {
  if(e.code === "Space") {
    e.preventDefault();
  }
}, false);

// Initialize - speaks welcome message every time page loads
window.addEventListener('load', async () => {
  await loadModels();
});

})();
</script>

</body>
</html>